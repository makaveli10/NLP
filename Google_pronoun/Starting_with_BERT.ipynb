{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport zipfile\nimport sys\nimport time\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['sample_submission_stage_1.csv', 'sample_submission_stage_2.csv', 'test_stage_2.tsv', 'test_stage_1.tsv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Refer this to get started with pre trained BERT**\n\nhttps://github.com/google-research/bert#pre-trained-models\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":2,"outputs":[{"output_type":"stream","text":"__notebook_source__.ipynb\r\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\nwith zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\", \"r\") as bert_zip_ref:\n    bert_zip_ref.extractall()\n!ls 'uncased_L-12_H-768_A-12'","execution_count":3,"outputs":[{"output_type":"stream","text":"--2019-05-20 17:18:00--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 64.233.184.128, 2a00:1450:400c:c0b::80\nConnecting to storage.googleapis.com (storage.googleapis.com)|64.233.184.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 407727028 (389M) [application/zip]\nSaving to: ‘uncased_L-12_H-768_A-12.zip’\n\nuncased_L-12_H-768_ 100%[===================>] 388.84M   130MB/s    in 3.0s    \n\n2019-05-20 17:18:03 (130 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n\nbert_config.json\t\t     bert_model.ckpt.index  vocab.txt\nbert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Download requirements to use pretrained BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py","execution_count":4,"outputs":[{"output_type":"stream","text":"--2019-05-20 17:19:40--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 37922 (37K) [text/plain]\nSaving to: ‘modeling.py’\n\nmodeling.py         100%[===================>]  37.03K  --.-KB/s    in 0.005s  \n\n2019-05-20 17:19:40 (6.88 MB/s) - ‘modeling.py’ saved [37922/37922]\n\n--2019-05-20 17:19:41--  https://raw.githubusercontent.com/google-research/bert/master/extract_features.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 13898 (14K) [text/plain]\nSaving to: ‘extract_features.py’\n\nextract_features.py 100%[===================>]  13.57K  --.-KB/s    in 0.005s  \n\n2019-05-20 17:19:41 (2.55 MB/s) - ‘extract_features.py’ saved [13898/13898]\n\n--2019-05-20 17:19:42--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12257 (12K) [text/plain]\nSaving to: ‘tokenization.py’\n\ntokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0s      \n\n2019-05-20 17:19:42 (75.8 MB/s) - ‘tokenization.py’ saved [12257/12257]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tokenization\nimport extract_features\nimport modeling\nimport tensorflow as tf","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Download data from GAP repo. The gap-validation.tsv file with 454 rows, and gap-test.tsv with 2000 rows, will be used for training. The gap-development.tsv data contains the same 2000 rows as test_stage_1.tsv data. So we'll make predictions on it."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\n!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\n!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\n!ls","execution_count":6,"outputs":[{"output_type":"stream","text":"--2019-05-20 17:19:55--  https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1075889 (1.0M) [text/plain]\nSaving to: ‘gap-test.tsv’\n\ngap-test.tsv        100%[===================>]   1.03M  --.-KB/s    in 0.03s   \n\n2019-05-20 17:19:55 (29.4 MB/s) - ‘gap-test.tsv’ saved [1075889/1075889]\n\n--2019-05-20 17:19:56--  https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1080993 (1.0M) [text/plain]\nSaving to: ‘gap-development.tsv’\n\ngap-development.tsv 100%[===================>]   1.03M  --.-KB/s    in 0.03s   \n\n2019-05-20 17:20:14 (29.8 MB/s) - ‘gap-development.tsv’ saved [1080993/1080993]\n\n--2019-05-20 17:20:15--  https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 245089 (239K) [text/plain]\nSaving to: ‘gap-validation.tsv’\n\ngap-validation.tsv  100%[===================>] 239.34K  --.-KB/s    in 0.02s   \n\n2019-05-20 17:20:15 (10.7 MB/s) - ‘gap-validation.tsv’ saved [245089/245089]\n\n__notebook_source__.ipynb  gap-test.tsv        uncased_L-12_H-768_A-12\n__pycache__\t\t   gap-validation.tsv  uncased_L-12_H-768_A-12.zip\nextract_features.py\t   modeling.py\ngap-development.tsv\t   tokenization.py\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_offset_no_space(text, offset):\n    count = 0\n    for position in range(offset):\n        if text[position] != \" \":\n            count += 1\n    return count\n\ndef count_chars_no_special(text):\n    count = 0\n    special_chars = [\"#\"]\n    for pos in range(len(text)):\n        if text[pos] not in special_chars:\n            count += 1\n    return count\n\ndef count_length_no_special(text):\n    count = 0\n    special_chars =[\"#\", \" \"]\n    for pos in range(len(text)):\n        if text[pos] not in special_chars:\n            count += 1\n    return count","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtain Contextual Embeddings for the target words. Run the below method 3 times for each of the dataset files"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_contextual_embeddings(data):\n    '''\n    Runs a forward propagation of BERT on input text, extracting contextual word embeddings\n    Input: data, a pandas DataFrame containing the information in one of the GAP files\n\n    Output: emb, a pandas DataFrame containing contextual embeddings for the words A, B and Pronoun. \n            Each embedding is a numpy array of shape (768)\n    columns: \"emb_A\": the embedding for word A\n             \"emb_B\": the embedding for word B\n             \"emb_P\": the embedding for the pronoun\n             \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n    '''\n    # take the text part and pass it to bert\n    text = data[\"Text\"]\n    text.to_csv(\"input.txt\", index=False, header=False)\n    \n    # extract_features.py runs forward propagation throught bert\n    \n    os.system(\"python3 extract_features.py \\\n              --input_file=input.txt \\\n              --output_file=output.jsonl \\\n              --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n              --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n              --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n              --layers=-1 \\\n              --max_seq_length=256 \\\n              --batch_size=8\")\n    bert_outs = pd.read_json(\"output.jsonl\", lines=True)\n    \n    # delete both files input.txt and output.jsonl\n    os.system(\"rm input.txt\")\n    os.system(\"rm output.jsonl\")\n    \n    index = data.index\n    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n    emb = pd.DataFrame(index=index, columns=columns)\n    emb.index.name = \"ID\"\n    \n    for i in range(len(data)):\n        P = data.loc[i, \"Pronoun\"].lower()\n        A = data.loc[i, \"A\"].lower()\n        B = data.loc[i, \"B\"].lower()\n        \n        # for each sentence count the offset not counting spaces\n        p_offset = compute_offset_no_space(data.loc[i, \"Text\"], data.loc[i, \"Pronoun-offset\"])\n        A_offset = compute_offset_no_space(data.loc[i, \"Text\"], data.loc[i, \"A-offset\"])\n        B_offset = compute_offset_no_space(data.loc[i, \"Text\"], data.loc[i, \"B-offset\"])\n        \n        # compute length\n        A_length = count_length_no_special(A)\n        B_length = count_length_no_special(B)\n        \n        emb_A = np.zeros(768)\n        emb_B = np.zeros(768)\n        emb_P = np.zeros(768)\n        \n        # init counts\n        count_chars = 0\n        count_A, count_B, count_C = 0, 0, 0\n        \n        # get bert embeddings for current line\n        bert_feat = pd.DataFrame(bert_outs.loc[i, \"features\"])\n        \n        # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n        # See if the character count until the current token matches the offset of any of the 3 target words\n        for j in range(2, len(bert_feat)):\n            token = bert_feat.loc[j, \"token\"]\n            if count_chars == p_offset:\n                emb_P += np.array(bert_feat.loc[j, \"layers\"][0]['values'])\n                count_chars += 1\n            \n            if count_chars in range(A_offset, A_offset + A_length):\n                emb_A += np.array(bert_feat.loc[j, \"layers\"][0]['values'])\n                count_A += 1\n            \n            if count_chars in range(B_offset, B_offset + B_length):\n                emb_B += np.array(bert_feat.loc[j, \"layers\"][0]['values'])\n                count_B += 1\n            count_chars += count_length_no_special(token)\n        \n        # Taking the average between tokens in the span of A or B, so divide the current value by the count\t\n        emb_A /= count_A\n        emb_B /= count_B\n        \n        label = \"None\"\n        if data.loc[i, \"A-coref\"] == True:\n            label = \"A\"\n        if data.loc[i, \"B-coref\"] == True:\n            label = \"B\"\n            \n        emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n    return emb\n        ","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the three dataset files pass them to the above method and get the bert embeddings for pronoun, A and B"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read file\nvalidation_data = pd.read_csv(\"gap-validation.tsv\", sep='\\t')\ntest_data = pd.read_csv(\"gap-test.tsv\", sep='\\t')\ndevelopment_data = pd.read_csv(\"gap-development.tsv\", sep='\\t')\n\n# get contextual embeddings from BERT pretrained\nvalidation_embeddings = get_contextual_embeddings(validation_data)\ntest_embeddings = get_contextual_embeddings(test_data)\ndevelopment_embeddings = get_contextual_embeddings(development_data)\n\n# write embeddings to json file\nvalidation_embeddings.to_json(\"validation_emb.json\")\ntest_embeddings.to_json(\"test_emb.json\")\ndevelopment_embeddings.to_json(\"dev_emb.json\")","execution_count":11,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in true_divide\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers, models, optimizers\nfrom keras import callbacks as k_callback\nfrom keras import backend as K\nfrom keras import constraints, initializers, regularizers\nfrom sklearn.model_selection import KFold, train_test_split, cross_val_score\nfrom sklearn.metrics import log_loss\nimport time\n\n# hyperparameters\nnum_units = 64\nlearning_rate = 0.001\ndropout_rate = 0.5\npatience = 100\nnfold = 5\nepochs = 1200\nlmbd = 0.1\nbatch_size = 32","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(input_shape):\n    input_ = layers.Input(shape=input_shape)\n    X = layers.Dense(units=num_units, name='dense_1')(input_)\n    X = layers.BatchNormalization(name='bn_1')(X)\n    X = layers.Activation('relu')(X)\n    X = layers.Dropout(dropout_rate, seed=7)(X)\n    \n    X = layers.Dense(units=num_units, name='dense_2')(X)\n    X = layers.BatchNormalization(name='bn_2')(X)\n    X = layers.Activation('relu')(X)\n    X = layers.Dropout(dropout_rate, seed=7)(X)\n    \n    X = layers.Dense(3, kernel_regularizer=regularizers.l2(lmbd), name='output_layer')(X)\n    X = layers.Activation('softmax')(X)\n    \n    model = models.Model(inputs=input_, outputs=X, name='classifier')\n    return model","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_json(embeddings):\n    '''\n    Parses the embeddigns given by BERT, and suitably formats them for the MLP model\n\n    Input: embeddings, a DataFrame containing contextual embeddings from BERT, \n           as well as the labels for the classification problem\n    columns: \"emb_A\": contextual embedding for the word A\n             \"emb_B\": contextual embedding for the word B\n             \"emb_P\": contextual embedding for the pronoun\n         \"label\": the answer to the coreference problem: \"A\", \"B\" or \"None\"\n\n    Output: X, a numpy array, for each line in the GAP file,\n            the concatenation of the embeddings of the target words\n            Y, a numpy array , for each line in the GAP file,\n            the one-hot encoded label\n            '''\n    embeddings.sort_index(inplace=True)\n    \n    # initialise X and Y\n    X = np.zeros((len(embeddings), 3*768))\n    Y = np.zeros((len(embeddings), 3))\n    \n    for i in range(len(embeddings)):\n        A = np.array(embeddings.loc[i, \"emb_A\"])\n        B = np.array(embeddings.loc[i, \"emb_B\"])\n        C = np.array(embeddings.loc[i, \"emb_P\"])\n        X[i] = np.concatenate((A, B, C))\n    \n    for i in range(len(embeddings)):\n        label = embeddings.loc[i, \"label\"]\n        if label == \"A\":\n            Y[i, 0] = 1\n        elif label == \"B\":\n            Y[i, 1] = 1\n        else:\n            Y[i, 2] = 1\n    return X, Y","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parse embeddings stored in json file using the abpve method to get in the format as required by the MLP model for all the three datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid = pd.read_json(\"validation_emb.json\")\nX_valid, Y_valid = parse_json(valid)\n\ndev = pd.read_json(\"dev_emb.json\")\nX_dev, Y_dev = parse_json(dev)\n\ntest = pd.read_json(\"test_emb.json\")\nX_test, Y_test = parse_json(test)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Nan, the offset of a target word is greater than the max_seq_length of BERT. are all Nans\ndev_nan = [row for row in range(len(X_dev)) if np.sum(np.isnan(X_dev[row]))]\nX_dev[dev_nan] = np.zeros(3*768)\n\ndev_val = [row for row in range(len(X_valid)) if np.sum(np.isnan(X_valid[row]))]\nX_valid = np.delete(X_valid, dev_val, axis=0)\nY_valid = np.delete(Y_valid, dev_val, axis=0)\n\ndev_test = [row for row in range(len(X_test)) if np.sum(np.isnan(X_test[row]))]\nX_test = np.delete(X_test, dev_test, axis=0)\nY_test = np.delete(Y_test, dev_test, axis=0)","execution_count":51,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenate test and validation datasets for training with K-fold cross validation. Using development dataset for testing."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((X_test, X_valid), axis=0)\nY_train = np.concatenate((Y_test, Y_valid), axis=0)\n\npredictions = np.zeros((len(X_dev), 3))","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KFold cross validation\nkfold = KFold(n_splits=nfold, shuffle=True, random_state=3)\nscores = []\nfor fold, (train_index, val_index) in enumerate(kfold.split(X_train)):\n    # print time of fold start\n    print(\"fold: {0}, time: {1}\".format(fold, time.ctime()))\n    \n    # split dataset\n    x_train, x_val = X_train[train_index], X_train[val_index]\n    y_train, y_val = Y_train[train_index], Y_train[val_index]\n    \n    # build mlp model\n    model = build_model([X_train.shape[1]])\n    model.compile(optimizer=optimizers.Adam(lr=learning_rate), loss='categorical_crossentropy')\n    callback = [k_callback.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)]\n    model.fit(x=x_train,\n             y=y_train,\n             batch_size=batch_size,\n             epochs=epochs,\n             callbacks=callback,\n             validation_data=(x_val, y_val),\n             verbose=0)\n    preds_validation = model.predict(x_val, verbose=0)\n    predictions += model.predict(X_dev, verbose=0)\n    \n    scores.append(log_loss(y_val, preds_validation))\npredictions /= nfold\nprint(\"Cross valid mean score: {0:.4f}, std: {1:.4f}\".format(np.mean(scores), np.std(scores)))\nprint(scores)\nprint(\"Test Scores: {0:.5f}\".format(log_loss(Y_dev, predictions)))\n    ","execution_count":53,"outputs":[{"output_type":"stream","text":"fold: 0, time: Mon May 20 20:20:24 2019\nfold: 1, time: Mon May 20 20:21:35 2019\nfold: 2, time: Mon May 20 20:22:47 2019\nfold: 3, time: Mon May 20 20:23:59 2019\nfold: 4, time: Mon May 20 20:25:14 2019\nCross valid mean score: 0.5704, std: 0.0203\n[0.5879626486705551, 0.5325747891016259, 0.5874970128186912, 0.5757299818127055, 0.5680406794058306]\nTest Scores: 0.53170\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission_stage_1.csv\", index_col = \"ID\")\nsubmission[\"A\"] = predictions[:, 0]\nsubmission[\"B\"] = predictions[:, 1]\nsubmission[\"NEITHER\"] = predictions[:, 2]\nsubmission.to_csv(\"submission_bert.csv\")","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}