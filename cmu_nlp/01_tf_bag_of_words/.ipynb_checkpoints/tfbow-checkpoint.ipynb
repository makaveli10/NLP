{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "from models import tfBoW\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "# read corpus\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "\n",
    "def read_dataset(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            tag, words = line.lower().strip().split(\" ||| \")\n",
    "            yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 16582\n",
      "No of tags: 5\n"
     ]
    }
   ],
   "source": [
    "train = list(read_dataset(\"../data/classes/train.txt\"))\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "dev = list(read_dataset(\"../data/classes/train.txt\"))\n",
    "nwords = len(w2i)\n",
    "ntags = len(t2i)\n",
    "print(\"Vocab size: {}\".format(nwords))\n",
    "print(\"No of tags: {}\".format(ntags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = tfBoW(nwords, ntags)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def train_step(words, tag):\n",
    "    with tf.GradientTape() as tape:\n",
    "        scores = model(words)\n",
    "        loss = loss_fn(tag, scores)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss/sent=0.0013, time=26.83s\n",
      "epoch 0: test acc=0.1715\n",
      "Epoch 1: train loss/sent=0.0013, time=28.87s\n",
      "epoch 1: test acc=0.1812\n",
      "Epoch 2: train loss/sent=0.0013, time=28.82s\n",
      "epoch 2: test acc=0.1946\n",
      "Epoch 3: train loss/sent=0.0013, time=24.34s\n",
      "epoch 3: test acc=0.1891\n",
      "Epoch 4: train loss/sent=0.0013, time=23.69s\n",
      "epoch 4: test acc=0.2052\n",
      "Epoch 5: train loss/sent=0.0013, time=23.67s\n",
      "epoch 5: test acc=0.2037\n",
      "Epoch 6: train loss/sent=0.0013, time=23.45s\n",
      "epoch 6: test acc=0.2138\n",
      "Epoch 7: train loss/sent=0.0013, time=23.43s\n",
      "epoch 7: test acc=0.2148\n",
      "Epoch 8: train loss/sent=0.0013, time=23.45s\n",
      "epoch 8: test acc=0.2170\n",
      "Epoch 9: train loss/sent=0.0013, time=23.50s\n",
      "epoch 9: test acc=0.2148\n",
      "Epoch 10: train loss/sent=0.0013, time=26.73s\n",
      "epoch 10: test acc=0.2148\n",
      "Epoch 11: train loss/sent=0.0013, time=27.16s\n",
      "epoch 11: test acc=0.2116\n",
      "Epoch 12: train loss/sent=0.0013, time=29.88s\n",
      "epoch 12: test acc=0.2096\n",
      "Epoch 13: train loss/sent=0.0013, time=23.99s\n",
      "epoch 13: test acc=0.2088\n",
      "Epoch 14: train loss/sent=0.0013, time=23.87s\n",
      "epoch 14: test acc=0.2101\n",
      "Epoch 15: train loss/sent=0.0013, time=28.82s\n",
      "epoch 15: test acc=0.2100\n",
      "Epoch 16: train loss/sent=0.0013, time=25.43s\n",
      "epoch 16: test acc=0.2097\n",
      "Epoch 17: train loss/sent=0.0013, time=25.34s\n",
      "epoch 17: test acc=0.2092\n",
      "Epoch 18: train loss/sent=0.0013, time=24.86s\n",
      "epoch 18: test acc=0.2051\n",
      "Epoch 19: train loss/sent=0.0013, time=25.03s\n",
      "epoch 19: test acc=0.2066\n",
      "Epoch 20: train loss/sent=0.0013, time=26.53s\n",
      "epoch 20: test acc=0.2044\n",
      "Epoch 21: train loss/sent=0.0013, time=23.91s\n",
      "epoch 21: test acc=0.2033\n",
      "Epoch 22: train loss/sent=0.0013, time=25.00s\n",
      "epoch 22: test acc=0.2046\n",
      "Epoch 23: train loss/sent=0.0013, time=23.94s\n",
      "epoch 23: test acc=0.2044\n",
      "Epoch 24: train loss/sent=0.0013, time=24.44s\n",
      "epoch 24: test acc=0.2049\n",
      "Epoch 25: train loss/sent=0.0013, time=24.49s\n",
      "epoch 25: test acc=0.2034\n",
      "Epoch 26: train loss/sent=0.0013, time=23.98s\n",
      "epoch 26: test acc=0.2033\n",
      "Epoch 27: train loss/sent=0.0013, time=24.15s\n",
      "epoch 27: test acc=0.2026\n",
      "Epoch 28: train loss/sent=0.0013, time=26.77s\n",
      "epoch 28: test acc=0.2025\n",
      "Epoch 29: train loss/sent=0.0013, time=32.08s\n",
      "epoch 29: test acc=0.2024\n",
      "Epoch 30: train loss/sent=0.0013, time=25.03s\n",
      "epoch 30: test acc=0.2026\n",
      "Epoch 31: train loss/sent=0.0013, time=24.88s\n",
      "epoch 31: test acc=0.2034\n",
      "Epoch 32: train loss/sent=0.0013, time=24.98s\n",
      "epoch 32: test acc=0.2028\n",
      "Epoch 33: train loss/sent=0.0013, time=25.96s\n",
      "epoch 33: test acc=0.2032\n",
      "Epoch 34: train loss/sent=0.0013, time=25.01s\n",
      "epoch 34: test acc=0.2028\n",
      "Epoch 35: train loss/sent=0.0013, time=24.80s\n",
      "epoch 35: test acc=0.2024\n",
      "Epoch 36: train loss/sent=0.0013, time=25.81s\n",
      "epoch 36: test acc=0.2028\n",
      "Epoch 37: train loss/sent=0.0013, time=23.57s\n",
      "epoch 37: test acc=0.2021\n",
      "Epoch 38: train loss/sent=0.0013, time=23.80s\n",
      "epoch 38: test acc=0.2017\n",
      "Epoch 39: train loss/sent=0.0013, time=24.19s\n",
      "epoch 39: test acc=0.2019\n",
      "Epoch 40: train loss/sent=0.0013, time=28.59s\n",
      "epoch 40: test acc=0.2020\n",
      "Epoch 41: train loss/sent=0.0013, time=25.29s\n",
      "epoch 41: test acc=0.2019\n",
      "Epoch 42: train loss/sent=0.0013, time=25.85s\n",
      "epoch 42: test acc=0.2019\n",
      "Epoch 43: train loss/sent=0.0013, time=25.03s\n",
      "epoch 43: test acc=0.2022\n",
      "Epoch 44: train loss/sent=0.0013, time=25.43s\n",
      "epoch 44: test acc=0.2012\n",
      "Epoch 45: train loss/sent=0.0013, time=25.37s\n",
      "epoch 45: test acc=0.2011\n",
      "Epoch 46: train loss/sent=0.0013, time=25.10s\n",
      "epoch 46: test acc=0.2013\n",
      "Epoch 47: train loss/sent=0.0013, time=24.70s\n",
      "epoch 47: test acc=0.2011\n",
      "Epoch 48: train loss/sent=0.0013, time=25.89s\n",
      "epoch 48: test acc=0.2000\n",
      "Epoch 49: train loss/sent=0.0013, time=23.65s\n",
      "epoch 49: test acc=0.2006\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    for words, tag in train:\n",
    "        words = tf.constant(words, dtype=tf.float32)\n",
    "        tag = tf.constant([tag], dtype=tf.float32)\n",
    "        loss = train_step(words, tag)\n",
    "#     loss_ = train_step(words, tag)\n",
    "    train_loss += loss.numpy()\n",
    "    print(\"Epoch %r: train loss/sent=%.4f, time=%.2fs\" % (\n",
    "                epoch, train_loss/len(train), time.time()-start_time))\n",
    "    test_correct = 0\n",
    "    for words, tag in dev:\n",
    "        words = tf.constant(words, dtype=tf.float32)\n",
    "        tag = tf.constant([tag], dtype=tf.float32)\n",
    "        scores = model(words)[0].numpy()\n",
    "        predict = np.argmax(scores)\n",
    "        if predict == tag:\n",
    "            test_correct += 1\n",
    "    print(\"epoch %r: test acc=%.4f\" % (epoch, test_correct/len(dev)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
